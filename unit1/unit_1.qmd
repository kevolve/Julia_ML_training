---
title: "Unit 1 - Your first day with the Julia language"
engine: julia
---

# Installation

The recommended way to install Julia is using [JuliaUp](https://github.com/JuliaLang/juliaup).
This is a program that allows you to maintain multiple Julia versions on your system simultaneously, and also helps update to newer versions as they become available.
Do not confuse this with the [package manager](https://docs.julialang.org/en/v1/stdlib/Pkg/), which is used to install packages within Julia.

For this course it is also recommended to install [Visual Studio Code](https://code.visualstudio.com/download), and the [Julia plugin for Visual Studio Code](https://www.julia-vscode.org/).
Once you have Julia installed, it's common to add a few packages to your Julia base environment.
In our case we install [IJulia.jl](https://github.com/JuliaLang/IJulia.jl) for running Julia in [Jupyter](https://jupyter.org/),
[Pluto.jl](https://github.com/fonsp/Pluto.jl) to try out [Pluto notebooks](https://plutojl.org/), [QuartoNotebookRunner.jl](https://github.com/PumasAI/QuartoNotebookRunner.jl) which integrates with [Quarto](https://quarto.org/) to create or update typeset notes like the ones you are currently reading,
and [Revise.jl](https://github.com/timholy/Revise.jl) which helps with development.

Finally, you may also want to clone this repo and instantiate a separate Julia environment for each unit of the course (we'll walk you through those steps soon).

In summary to install Julia and the supporting software, follow these steps.

1. Install Julia (and JuliaUp). Follow the instructions in the [Official Julia installation page](https://julialang.org/install/). You'll run a shell script (Mac/Linux) or use the Microsoft store on Windows. Once installed, restart your terminal, after which `juliaup` and `julia` should be available in your terminal. Then try,
    a. In the terminal run `juliaup` and you should see a short help listing.
    b. In the terminal try `julia` in the command line and you should enter the Julia REPL (Read Evaluate Print Loop). You should see a prompt, `julia> ` and try `1+1` and hit ENTER. To exit hit Ctrl+D, or `exit()` followed by ENTER. 
Note that this course was created with Julia version 1.11.5.
You can see the version of Julia that you are running when you first run Julia, or by running `versioninfo()` in the Julia REPL.
2. Install [Visual Studio Code](https://code.visualstudio.com/download) if you don't already have it installed.
3. Install the [Julia plugin for Visual Studio Code](https://www.julia-vscode.org/). See instructions [here](https://www.julia-vscode.org/docs/dev/gettingstarted/#Installing-the-Julia-extension).
4. Install the above mentioned Julia packages into your base environment. You can do this for each of the packages using the package manager as follows.
    a. Run `julia` and enter package manager mode by hitting `]`. You should see the prompt change to `(@vX.X) pkg>` where X.X is the julia version you have installed.
    b. Type `update` and ENTER to update the list of available packages from the registry.
    c. Type `add IJulia` and ENTER to install IJulia.jl. 
    d. Similarly `add Pluto` to install Pluto.jl. 
    e. Similarly `add QuartoNotebookRunner` to install QuartoNotebookRunner.jl. In each case you can use TAB to autocomplete (or hit TAB twice to see all available options).
    f. Similarly `add Revise`.


# First steps: Finding the max (loops, functions, variables, plotting)

Let's dive directly into some code. Here you can see:

* Using a Julia package with the `using` keyword. In this case, we use the `Random` package: one of the standard library packages (that come with Julia).
* Creation of a function, with the `function` keyword, and returning a result with the `return` keyword.
* A `for` loop.
* A conditional (`if`) statement.
* A few more language features. 

```{julia}
using Random

function find_max(data)
    max_value = -Inf
    for x âˆˆ data # You cna type âˆˆ by typing \in + [TAB]. Could have just used `in` as well
        if x > max_value
            max_value = x
        end
    end
    return max_value
end

Random.seed!(0)
data = rand(100)
max_value = find_max(data)
println("Found maximal value: $(max_value)")
```

You of course don't need to implement such elementary functions, since most are supplied with the language, for example:

```{julia}
maximum(data)
```

You can get help for a function by typing `? maximum` in the REPL or in Jupyter. 

Related built-in functions that may be of interest are `findmax`, `argmax`, and `max`. Similarly there are counterparts for `min` in place of max (`minimum`, `findmin`, `argmin`, and `min`). There is also `minmax`, and `extrema`. Look at the help for some of these functions and try some of the examples.  

## Some fun probability

Let's see how many times we get a new record when we scan for the maximum.

```{julia}
function find_max(data)
    max_value = -Inf
    n = 0
    for x in data
        if x > max_value
            n += 1
            max_value = x
        end
    end
    return max_value, n # Returns a tuple
end

max_value, n = find_max(data)
println("Found maximal value: $(max_value)")
println("There were $n records along the way.")
```

**If the data is i.i.d., how many times does this happen on average?**

Denote the number of records for $n$ data points by $X_n$ then,
$$
X_n = I_1 + I_2 + \ldots + I_n
$$
where,
$$
I_i =
\begin{cases}
1 & \text{if the}~i~\text{-th data point is a record}, \\
0 & \text{otherwise}.
\end{cases}
$$
Now,
$$
{\mathbb E}[X_n] = {\mathbb E}[I_1] + {\mathbb E}[I_2] + \ldots + {\mathbb E}[I_n]. 
$$
Observe that ${\mathbb E}[I_i] = {\mathbb P}(I_i = 1)$ and for statistically independent and identically distributed data points we have,
$$
{\mathbb P}(I_i = 1) = \frac{1}{i},
$$
Hence,
$$
{\mathbb E}[X_n] = h_n = \sum_{i=1}^n \frac{1}{i},
$$
the harmonic sum. It is known that
$$
h_n = \log(n) + \gamma + o(1),
$$
where $\gamma$ is the [Eulerâ€“Mascheroni constant](https://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant) and $o(1)$ is a term that vanishes as $n \to \infty$. That is 
$$
h_n \approx \log(n) + \gamma.
$$

## Experimenting


Let's see it...
```{julia}
println("Î³ = ",Float64(MathConstants.Î³))  # \gamma + [TAB]
println()

# These are one-line function definitions
h(n) = sum(1/i for i in 1:n)
approx_h(n) = log(n) + MathConstants.Î³

for n in 1:10
    println(n, "\t", round(h(n), digits = 4), "\t", round(approx_h(n), digits = 4) )
end


```

Let's plot the error of the approximation as $n$ grows.

```{julia}
using Plots
err = [h(n) - approx_h(n) for n in 1:20] # This is a comprehension
scatter(1:20, err, xticks=1:20, 
        xlabel="n", ylabel = "Error", ylim = (0,0.5), legend=false)
```


Let's verify via a Monte Carlo simulation and also estimate the distribution:

```{julia}
using Statistics

records = []

data_n = 10^2
num_sims = 10^5

for s in 1:num_sims
    Random.seed!(s)
    data = rand(data_n)
    _, n = find_max(data)
    push!(records,n)
end

approx_value = approx_h(data_n)
mc_value = mean(records)

println("log($data_n) + Î³ =  $(approx_value), Monte Carlo Estimate: $(mc_value)")

histogram(records, xticks = 1:maximum(records), nbins = maximum(records), 
                normed=true, xlabel="Num Records", ylabel="Probability", legend=false)
```

# About Julia

- **Origins and History**
  - Julia was conceived in 2009 by Jeff Bezanson, Stefan Karpinski, Viral B. Shah, and Alan Edelman.
  - First publicly released in 2012, with the promise to be â€œas fast as C, as easy as Python, as flexible as Ruby, and as powerful for statistics as R.â€
  - Born out of dissatisfaction with existing technical computing languages for scientific and numerical computing.

- **Core Idea**
  - Designed for high-performance numerical and scientific computing.
  - Combines the ease of use of dynamic languages (like Python or R) with performance close to statically-typed, compiled languages (like C and Fortran).
  - Uses Just-In-Time (JIT) compilation via LLVM, meaning code is compiled to efficient machine code at runtime.

- **Key Benefits**
  - **Speed:** Approaches or matches C/Fortran in performance for many tasks.
  - **Multiple Dispatch:** Allows defining function behavior across combinations of argument types, enabling more expressive and extensible code.
  - **Rich Ecosystem:** Growing collection of packages for data science, machine learning, optimization, and visualization.
  - **Easy Syntax:** Friendly to users familiar with Python, MATLAB, or R.
  - **Metaprogramming:** Powerful features like macros for generating and transforming code.
  - **Native Parallelism:** Designed with parallel and distributed computing in mind from the start.
  - **Interoperability:** Easily calls C, Fortran, and Python libraries for leveraging existing codebases.

## Key Julia "Communities"

**Where to get help**

* [The Julia Language Slack](https://julialang.org/slack/)
* [Julia Discourse](https://discourse.julialang.org/)

**Special Domains:**

* Operations Research: [JUMP](https://jump.dev/)
* Scientific Machine Learning: [SciML](https://sciml.ai/)
* Statistics: [Julia Statistics](https://github.com/JuliaStats)
* Machine Learning: [Julia ML](https://juliaml.github.io/)
* Climate modelling: [CliMA](https://clima.caltech.edu/)
* GPUs: [JuliaGPU](https://juliagpu.org/)

**Companies:**

* JuliaHub (used to be "Julia Computing"): [juliahub.com](https://juliahub.com/)
* PumasAI: [pumas.ai](https://pumas.ai/)
* Fugro Roames: [case study](https://juliahub.com/industries/case-studies/fugro-roames-ml)

**Books:**

* [Algorithms for Optimization](https://mitpress.mit.edu/9780262039420/algorithms-for-optimization/) by Mykel J. Kochenderfer and Tim A. Wheeler.
* [Statistics with Julia](https://statisticswithjulia.org/) by Yoni Nazarathy and Hayden Klok.

# Where to run Julia

## Shell

```
shell> echo "println(\"Hello world!\")" > temp.jl
shell> julia temp.jl
Hello world
```

Try `julia --help` to see options. 

## The REPL (Read Evaluate Print Loop)

```
shell> julia
               _
   _       _ _(_)_     |  Documentation: https://docs.julialang.org
  (_)     | (_) (_)    |
   _ _   _| |_  __ _   |  Type "?" for help, "]?" for Pkg help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 1.11.5 (2025-04-14)
 _/ |\__'_|_|_|\__'_|  |  Official https://julialang.org/ release
|__/                   |

julia> 
```

At the prompt:
* Hitting `]` changes to package manager mode. 
* Hitting `;` changes to shell mode.
* Hitting `?` changes to help mode.
* Hitting `BACKSPACE` changes back to `julia>` mode.

Useful function for running code: `include`. Try: `include("temp.jl")`. Related are the `using` and `import` keywords.

## Visual Studio Code

The Julia extension makes VS-Code IDE (integrated development environment). Not quite R-Studio, but close.

- **Syntax highlighting:** Provides rich syntax highlighting for Julia code.
- **Code completion:** Offers IntelliSense, code completion, and signature help.
- **Integrated REPL:** Launch and interact with a Julia REPL directly in VS Code.
- **Debugger support:** Includes a full-featured debugger with breakpoints, stepping, and variable inspection. Not commonly used.
- **Plot pane:** View plots and figures inline within the VS Code editor.
- **Dataframe preview:** View dataframes (tables).
- **Workspace view:** Explore variables, data, and modules in your current environment.
- **Environment/project integration:** Works seamlessly with Juliaâ€™s package and environment management.
- **Notebook support:** Compatible with Jupyter notebooks via the VS Code Jupyter extension.
- **Hover/documentation:** View function/type docs and use jump-to-definition.
- **Actively maintained:** The extension is regularly updated and supported by the Julia community.

**Shortcuts:**

QQQQ-check these shortcuts

- **Start Julia REPL:** `Ctrl+Shift+P` â†’ type and select `Julia: Start REPL`
- **Execute active file in REPL:** `Ctrl+Shift+P` â†’ type and select `Julia: Execute File in REPL`
- **Send code to REPL:** `Shift+Enter`
- **Execute cell or selected lines:** `Alt+Enter`
- **Go to definition:** `F12`
- **Find references:** `Shift+F12`
- **Show documentation (hover):** `Ctrl+K Ctrl+I` (or just hover cursor over symbol)
- **Run code cell above/below:** `Ctrl+Alt+Up` / `Ctrl+Alt+Down`
- **Set breakpoint (in debug mode):** `F9`
- **Step over (in debug mode):** `F10`
- **Step into (in debug mode):** `F11`
- **Continue (in debug mode):** `F5`

## Jupyter

This is standard machine learning way of exploring and communicating ideas. 
The 'J' in "Jupyter" actually stands for "Julia". 
But the Julia community uses Jupyter a bit less (yet the course instructors are certainly avid users).

## Pluto.jl

While both Pluto.jl and Jupyter are interactive notebook environments for Julia, Pluto.jl is fundamentally reactiveâ€”changing a variable or a cell instantly updates all dependent cells throughout the notebook, ensuring consistency and minimizing hidden state issues. In contrast, Jupyter notebooks execute cells in the order chosen by the user, which can sometimes lead to hard-to-debug inconsistencies if cells are run out of order. Pluto notebooks have a more streamlined, Julia-specific design and promote reproducibility by making cell dependencies explicit, whereas Jupyter offers broader language support and a larger ecosystem of extensions but does not provide the same level of reactive interactivity or strict cell dependency mapping as Pluto.jl.

There was even a conference! [PlutoCon2021](https://plutojl.org/plutocon2021/).

```
julia> using Pluto
â”Œ Info: 
â”‚   Welcome to Pluto v0.20.8 ðŸŽˆ
â”‚   Start a notebook server using:
â”‚ 
â”‚ julia> Pluto.run()
â”‚ 
â”‚   Have a look at the FAQ:
â”‚   https://github.com/fonsp/Pluto.jl/wiki
â”” 
```

## Quarto

A modern R-markdown style environment. Used to make this course!  Has good Julia integration. See for example [Pumas Tutorials](https://tutorials.pumas.ai/) that make extensive use of Quarto.

A legacy related framework is [Weave.jl](https://github.com/JunoLab/Weave.jl).

## Integrations

Integrations within Python and R. See below.

# The Package Manager

* REPL via `]`
* The `Pkg` package

## Environment/package management in Julia

Python <> Julia correspondence?

`julia --project` OR `julia` then `]` then `activate .`

Then `instantiate` to do `pip install -r requirements.txt` but it's better

`source venv/bin/active && pip install -r requirements.txt` <> `julia --project > ] > instantiate`

# Story: Computing Square Roots (multiple dispatch, types, LLVM)

The `sqrt` function. 

```{julia}
sqrt(25)
```

Cal also use an alias for `sqrt`:

```{julia}
âˆš25 #\sqrt + [TAB]
```

```{julia}
x = sqrt(2)
@show x, x^2

x = sqrt(2f0) #32 bit float (Float32)
@show x, x^2
```

What if we try $\sqrt{-1}$?

```{julia}
sqrt(-1)
```

But if we give a complex type as input:

```{julia}
sqrt(Complex(-1))
```

In Julia a **function** (such as `sqrt` or its alias `âˆš`) can have **many methods**:

```{julia}
methods(sqrt)
```

```{julia}
using InteractiveUtils
@which sqrt(2)
```

```{julia}
@which sqrt(2.0)
```

```{julia}
@which sqrt(Ï€*im) #\pi + [Tab]
```

What if we wanted to apply square root to several/many elements together? It is common to use the `.` broadcast operator.

```{julia}
data = [i^2 for i in 0:10]
sqrt.(data) # The "." broadcating operator
```

```{julia}
x = 36
@show x^0.5
```

In Julia's source code, in [`math.jl`](https://github.com/JuliaLang/julia/blob/7b64cec5385d9099762ad7449c340eaac4fccb41/base/math.jl#L626) you'll find the following in lines 626-629:

```
@inline function sqrt(x::Union{Float32,Float64})
    x < zero(x) && throw_complex_domainerror(:sqrt, x)
    sqrt_llvm(x)
end
```


```{julia}
@code_lowered sqrt(2.5)
```

Here `sqrt_llvm()` compiles to [Low Level Virtual Machine(LLVM)](https://en.wikipedia.org/wiki/LLVM), so while many functions in Julia are actually implemented in Julia, with square roots it is better to let the underlying low level (LLVM) code handle square roots because it is later changed to assembly code; which is very fast. You can inspect this via the macros `@code_llvm` and `@code_native`.  

This will generally look the same on different computer types (LLVM is hardware agnostic):

```{julia}
@code_llvm sqrt(2.5)
```

This will look different for different computer types (cpus):

```{julia}
@code_native sqrt(2.5)
```

However, what if we wanted to do square roots via software? For example,

```{julia}
sqrt(big(10)^100)
```

What are (in principle) some [methods to compute square roots](https://en.wikipedia.org/wiki/Methods_of_computing_square_roots)? Let's look at them and implement them.

One method is the [Babylonian algorithm](https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method): Say we are given a positive real number $z$ and want its square root. We start with an initial guess $x_0$. We then apply the recursive step,

$$
x_{k+1} = \frac{1}{2}\Big(x_k+\frac{z}{x_k}\Big).
$$
That is, at each step the next iterate is the arithmetic mean of the previous iterate, $x_k$, and $z/x_k$. The Babylonian algorithm runs this iteration until convergence (note the default initial guess in this implementation is $z/2$):

```{julia}
function bab_sqrt(z ; init_x = z/2, verbose = false, tol = 1e-10)
    x = init_x
    while true
        verbose && println("Babylonian iterate: $x")
        next_x = 0.5*(x + z / x)
        abs(next_x - x) < tol && break
        x = next_x
    end
    x
end

bs, s = bab_sqrt(5000;verbose = true), sqrt(5000)
println("Babylonian:\t$bs\nSystem:\t\t$s")
```

## Newton's method

We can view the ancient Babylonian method as an application of the more general [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method) for solving equations. Our goal is to solve $x^2 = z$ where $z$ is given and $x$ is desired. That is define $f(x) = x^2 - z$ and we wish to find the solution of $f(x) = 0$. Newton's method iterates,

$$
x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)},
$$

based on an affine (linear) approximation of $f(\cdot)$ at the point $x_k$. Here $f'(\cdot)$ is the derivative, which in our case is $f'(x) = 2x$. So Newton's iterates for finding the square root are,

$$
x_{k+1} = x_k - \frac{x_k^2-z}{2 x_k} = \frac{x_k}{2} + \frac{z}{2x_k} = \frac{1}{2}\Big(x_k+\frac{z}{x_k}\Big).
$$

```{julia}
function newton(f, x_0::Real, der_f; Îµ = 10e-5, maxiter = 100) #\varepsilon
    x = x_0
    x_prev = x + 2Îµ
    iter = 0
    while abs(x-x_prev) â‰¥ Îµ #\ge
        x_prev = x
        x = x - f(x)/der_f(x)
        iter += 1
        if iter == maxiter 
            @info "Maximal number of iterations reached"
            break
        end
    end
    return x
end

my_root2 = newton((x)->(x^2 - 2), 3, (x)->2x)
@show my_root2
@show âˆš2
âˆš2 â‰ˆ my_root2  #\approx
```

What if we don't (easily) know the derivative?
```{julia}
f(x) = sqrt(log(sin(exp(cos((x/5)^2)*log(x/5)+x^7))) + 1)-1/2
plot(f,xlim=(0.95,1.05), xlabel = "x", ylabel="f(x)", label=false)
```

Let's use automatic differentiation (see for example Section 4.4 [here](https://deeplearningmath.org/)).

```{julia}
using ForwardDiff: derivative
auto_der = derivative(f, 0.95)

h_val = 0.0001
numer_der = (f(0.95+h_val) - f(0.95-h_val))/(2h_val)
auto_der, numer_der
```

```{julia}
function newton(f, 
                x_0::Real, 
                der_f  = (x)->derivative(f, x); 
                Îµ = 10e-8, 
                maxiter = 100)
    x = x_0
    x_prev = x + 2Îµ
    iter = 0
    while abs(x-x_prev) â‰¥ Îµ
        x_prev = x
        x = x - f(x)/der_f(x)
        iter += 1
        if iter == maxiter 
            @info "Maximal number of iterations reached"
            break
        end
    end
    return x
end

root_point = newton(f,0.95)
println("Found root: $root_point")
plot(f,xlim=(0.95,1.05), xlabel = "x", ylabel="f(x)", label=false)
scatter!([root_point], [0], color=:red, marker=:circle, label="Root found")
```

# Story: Computing Factorials (special functions, big numbers, more on types)

* Basics
* Recursion
* BigInts
* The Gamma function
* Accuracy of the Stirling approximation (will use arrays also for plotting)

A few basic ways to compute $10! = 1\cdot 2 \cdot \ldots \cdot 10$:

```{julia}
f_a = factorial(10)
@show f_a

f_b = *(1:10...)
@show f_b

f_c = last(accumulate(*,1:10))
@show f_c

f_d = 1
for i in 1:10
    global f_d *= i
end
@show f_d;
```

Observe that,

$$
n! = 
\begin{cases}
n \cdot (n-1)! & n = 1,2,\ldots\\
1 & n = 0.
\end{cases}
$$

This is a recursive definition. Let's implement it:

```{julia}
function my_factorial(n)
    if n == 0
        return 1
    else
        return n * my_factorial(n-1)
    end
end

my_factorial(10)
```

Let's see what happens with this recursion:

```{julia}
function my_factorial(n)
    println("Calling my_factorial($n)")
    if n == 0
        ret_val = 1
    else
        ret_val = n * my_factorial(n-1)
    end
    println("Returning from the call of my_factorial($n)")
    ret_val
end

my_factorial(10)
```
You can also use the [`stracktrace()`](https://docs.julialang.org/en/v1/manual/stacktraces/) function.


Here is the `my_factorial()` function (written compactly).

```{julia}
my_factorial(n) = n == 0 ? 1 : n*my_factorial(n-1)

my_factorial(10)
```

Such compact writing does not change what actually happens under the hood. To see this consider both forms:

```{julia}
my_factorial1(n) = n == 0 ? 1 : n*my_factorial1(n-1)

function my_factorial2(n)
    if n == 0
        return 1
    else
        return n * my_factorial2(n-1)
    end
end
```

And use Julia's `@code_lowered` macro to see how Julia parses the code into an intermediate representation (before being further compiled to LLVM). In both forms we get the exact same intermediate form.

```{julia}
@code_lowered my_factorial1(10)
```

```{julia}
@code_lowered my_factorial2(10)
```

How large can factorials we compute be? With `BigInt`, created via `big()`, there is sometimes no limit, but if we wanted to stay within the machine word size, we stay with `Int64` (with Julia `Int` is either `Int32` on "32 bit machines" or `Int64` on "64 bit machines). But even 32 bit machines support 64 bit integers (by doubling words).

Lets first use [Stirling's approximation](https://en.wikipedia.org/wiki/Stirling%27s_approximation) to get an estimate of the largest factorial we can compute with `UInt64`.

$$
n! \sim \sqrt{2 \pi} \, n^{n+\frac{1}{2}} e^{-n}
$$

To see the approximation isn't unreasonable, observe that $n! \le n^n$ (why?) but isn't so far either. 
```{julia}
#An array of named tuples (note that "n!" is just a name)
[(n! = factorial(n), n2n = n^n, ratio = factorial(n)/(n^n)) for n in 1:10]
```

The other $\sqrt{n} e^{-n}$ factor of $n$ in Stirling, corrects for this and $\sqrt{2 \pi}$ is a constant.


```{julia}
stirling(n) = (âˆš(2Ï€*n))*(n/MathConstants.e)^n      

[(  n! = factorial(n), 
    stirling = stirling(n), 
    ratio = round(factorial(n)/stirling(n),digits = 5)) 
    for n in 1:10]
```

So let's use Stirling to see how big $n$ can be to fit in `UInt64`. That is solve 
$$
\sqrt{2 \pi} \, n^{n+\frac{1}{2}} e^{-n}  = 2^{64}-1.
$$
There are multiple ways to try to do this. We'll use floating point numbers and just search. Observe this:

```{julia}
2^64-1, typeof(2^64-1) #This is a signed integer by default
```

```{julia}
UInt(2)^64-1, typeof(UInt(2)^64-1) #unsigned
```

```{julia}
println(UInt(2)^64-1)
```

See also the documentation about [Integers and Floating-Point Numbers](https://docs.julialang.org/en/v1/manual/integers-and-floating-point-numbers/#Integers-and-Floating-Point-Numbers).

With floating point we can do much more:
```{julia}
2.0^64-1, typeof(2.0^64-1)
```
In general,
```{julia}
@show typemax(Int64)
@show typemax(UInt64)
@show typemax(Float64);
```

Here is the search (to simplify let's focus on signed integers): 

```{julia}
limit = typemax(Int64)
n = 1
while stirling(n) <= limit
    global n += 1
end
n -= 1 #why is this here? What can be done instead?
println("Found maximal n for n! with 64 bits to be $n.")
```

Let's try it:

```{julia}
factorial(20)
```

What about $n=21$?

```{julia}
factorial(21)
```

Indeed $n=21$ doesn't fit within the 64 bit limit.  However as suggested by the error message, using `big()` can help:

```{julia}
typeof(big(21))
```

```{julia}
factorial(big(21))
```

With (software) big integers everything goes:

```{julia}
n = 10^3
big_stuff = factorial(big(n));
num_digits = Int(ceil(log10(big_stuff))) 
println("The facotrial of $n has $num_digits decimal digits.") 
```

What about factorials of numbers that aren't positive integers?

```{julia}
factorial(6.5)
```

No, that isn't defined. But you may be looking for the [gamma](https://en.wikipedia.org/wiki/Gamma_function) special function:

$$
\Gamma(z)=\int_{0}^{\infty} x^{z-1} e^{-x} d x.
$$

```{julia}
using SpecialFunctions #You'll need to add (install) SpecialFunctions

gamma(6.5)
```

To feel more confident this value agrees with the integral definition of $\Gamma(\cdot)$; let's compute the integral in a very crude manner ([Riemann_sum](https://en.wikipedia.org/wiki/Riemann_sum)):

```{julia}
function my_crude_gamma(z; delta= 0.01, M = 50)
    integrand(x) = x^(z-1)*exp(-x) 
    x_grid = 0:delta:M
    sum(delta*integrand(x) for x in x_grid)
end

my_crude_gamma(6.5)
```
Now note that the gamma function is sometimes considered as the continuous version of the factorial because,
$$
\begin{aligned}
\Gamma(z+1) &=\int_{0}^{\infty} x^{z} e^{-x} d x \\
&=\left[-x^{z} e^{-x}\right]_{0}^{\infty}+\int_{0}^{\infty} z x^{z-1} e^{-x} d x \\
&=\lim _{x \rightarrow \infty}\left(-x^{z} e^{-x}\right)-\left(-0^{z} e^{-0}\right)+z \int_{0}^{\infty} x^{z-1} e^{-x} d x \\
&=z \, \Gamma(z).
\end{aligned}
$$

That is, the recursive relationship $\Gamma(z+1) = z\Gamma(z)$ holds similarly to $n! = n \cdot n!$. Further 
$$
\Gamma(1) = \int_0^\infty e^{-x} \, dx = 1.
$$
Hence we see that for integer $z$, $\Gamma(z) = (z-1)!$ or $n! = \Gamma(n+1)$. Let's try this.

```{julia}
using SpecialFunctions
[(n = n, n! = factorial(n), Î“ = gamma(n+1)) for n in 0:10]
```

The gamma function can also be extended outside of the positive reals. At some points it isn't defined though.

```{julia}
@show gamma(-1.1) #here defined.
gamma(-1) #here not defined
```

Here is a plot where we exclude certain points where it isn't defined

```{julia}
using Plots, SpecialFunctions

z = setdiff(-3:0.001:4, -3:0) #setdifference to remove points where gamma() returns a NaN   
plot(z,gamma.(z), ylim=(-7,7),legend=false,xlabel="z",ylabel = "Î“(z)")
```

QQQQ - Put in `eps()` computation

QQQQ - Put in type hierarchy

# Integrating with R and Python

