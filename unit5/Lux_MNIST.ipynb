{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785ad9bf-8b44-42f9-8e7d-3bb5431fd512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/git/Julia_ML_training/unit5/Project.toml`\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[cbdf2221] \u001b[39mAlgebraOfGraphics v0.10.7\n",
      "  \u001b[90m[336ed68f] \u001b[39mCSV v0.10.15\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[13f3f980] \u001b[39mCairoMakie v0.13.9\n",
      "  \u001b[90m[a93c6f00] \u001b[39mDataFrames v1.7.0\n",
      "  \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.120\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[587475ba] \u001b[39mFlux v0.16.3\n",
      "  \u001b[90m[38e38edf] \u001b[39mGLM v1.9.0\n",
      "  \u001b[90m[60bf3e95] \u001b[39mGLPK v1.2.1\n",
      "  \u001b[90m[09f84164] \u001b[39mHypothesisTests v0.11.5\n",
      "  \u001b[90m[4076af6c] \u001b[39mJuMP v1.26.0\n",
      "  \u001b[90m[23fbe1c1] \u001b[39mLatexify v0.16.8\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[b2108857] \u001b[39mLux v1.13.0\n",
      "  \u001b[90m[eb30cadb] \u001b[39mMLDatasets v0.7.18\n",
      "  \u001b[90m[add582a8] \u001b[39mMLJ v0.20.8\n",
      "  \u001b[90m[f1d291b0] \u001b[39mMLUtils v0.4.8\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[ee78f7c6] \u001b[39mMakie v0.22.9\n",
      "  \u001b[90m[ff71e718] \u001b[39mMixedModels v4.35.2\n",
      "  \u001b[90m[6f286f6a] \u001b[39mMultivariateStats v0.10.3\n",
      "  \u001b[90m[636a865e] \u001b[39mNearestNeighborModels v0.2.3\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[429524aa] \u001b[39mOptim v1.12.0\n",
      "  \u001b[90m[3bd65402] \u001b[39mOptimisers v0.4.6\n",
      "  \u001b[90m[92933f4c] \u001b[39mProgressMeter v1.10.4\n",
      "  \u001b[90m[ce6b1742] \u001b[39mRDatasets v0.7.7\n",
      "  \u001b[90m[2913bbd2] \u001b[39mStatsBase v0.34.5\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[0c5d862f] \u001b[39mSymbolics v6.40.0\n",
      "  \u001b[90m[9e3dc215] \u001b[39mTimeSeries v0.24.2\n",
      "  \u001b[90m[e88e6eb3] \u001b[39mZygote v0.7.10\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f29092-6074-4d5f-b65a-934395317f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux\n",
    "using Zygote # The primary automatic differentiation engine\n",
    "using Optimisers # The new standard for optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdfe1b8-ac04-484d-8e65-2abf9ecca387",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using MLUtils # Provides the DataLoader\n",
    "using Statistics\n",
    "using Random\n",
    "using ProgressMeter\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy # Import the needed utilities from Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c4ff98-291a-458d-b71c-68b683985db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProgressMeter.ijulia_behavior(:append);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecb0f71-5b82-4dfc-84e9-6b4564e2edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "const rng = Random.default_rng()\n",
    "Random.seed!(rng, 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc60fea-dd1f-4978-86e8-9263fd662f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "num_epochs = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e774f0-16f9-4f98-b461-0ffb62fb8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_raw, train_y_raw = MNIST(split=:train)[:]\n",
    "test_x_raw,  test_y_raw  = MNIST(split=:test)[:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f77503-5091-4346-b5a6-c4306a43a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing is identical\n",
    "function preprocess_features(x)\n",
    "    return Float32.(reshape(x, 28*28, :))\n",
    "end\n",
    "\n",
    "train_x = preprocess_features(train_x_raw)\n",
    "test_x = preprocess_features(test_x_raw)\n",
    "train_y = onehotbatch(train_y_raw, 0:9)\n",
    "test_y = onehotbatch(test_y_raw, 0:9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21561a98-83aa-4f43-a46a-59d180653f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataLoader from MLUtils\n",
    "train_loader = DataLoader((train_x, train_y), batchsize=batch_size, shuffle=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9140dc4-c19c-4588-8cd2-92b74a4a18c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "    layer_1 = Dense(784 => 128, relu),  \u001b[90m# 100_480 parameters\u001b[39m\n",
       "    layer_2 = Dense(128 => 64, relu),   \u001b[90m# 8_256 parameters\u001b[39m\n",
       "    layer_3 = Dense(64 => 10),          \u001b[90m# 650 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: \u001b[39m109_386 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Model Definition and Initialization (Key Lux difference) ---\n",
    "\n",
    "# Define the model structure. It looks similar to Flux's Chain.\n",
    "# Note the `=>` syntax for Dense layers.\n",
    "model = Chain(\n",
    "      Dense(28*28 => 128, relu),  # Input: 784 -> Hidden 1: 128 neurons\n",
    "      Dense(128 => 64, relu),     # Hidden 1: 128 -> Hidden 2: 64 neurons\n",
    "      Dense(64 => 10)              # Hidden 2: 64 -> Output: 10 logits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2766a56-c8c2-4758-bf03-1ed34f56b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Lux, we explicitly initialize the parameters (ps) and state (st).\n",
    "# This is a core concept: the model structure is separate from its learnable parts.\n",
    "ps, st = Lux.setup(rng, model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a98c1a-2033-485e-97b9-7a591e5834cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(layer_1 = (weight = Float32[-0.10921513 0.056196645 … 0.110608466 0.057007626; -0.011075623 -0.112844504 … -0.052739404 0.046212457; … ; 0.040891483 0.018354304 … 0.087309256 0.091325976; -0.011361991 -0.09112135 … -0.122030705 -0.11557871], bias = Float32[0.0125793945, -0.024275485, 0.03424715, 8.1130434f-5, -0.02638943, -0.034375455, -0.010637262, 0.025727345, 0.016990406, 0.011116858  …  -0.031849086, -0.021829436, 0.0001961163, 0.022090366, -0.025813958, -0.007818311, 0.018396122, -0.012626337, 0.01134666, 0.0288197]), layer_2 = (weight = Float32[0.2037279 0.121231 … 0.2081713 -0.26592368; 0.10215899 0.30275932 … -0.13877812 0.28471065; … ; -0.030344477 0.09217859 … 0.0432775 -0.19036081; -0.1642193 0.20556633 … 0.06377395 -0.094860405], bias = Float32[-0.06744722, -0.010483333, 0.08303247, -0.07705071, 0.077265754, -0.00868912, -0.04639269, 0.035928313, 0.0037759468, 0.027657595  …  0.01394165, -0.025066027, 0.06153464, 0.0838878, 0.07016804, 0.005167151, -0.020277672, -0.05315493, -0.030773805, -0.0069199014]), layer_3 = (weight = Float32[-0.20943005 -0.053786363 … -0.20925115 0.025262095; -0.19690584 -0.20615919 … -0.037661117 0.16484034; … ; -0.12223925 -0.1302812 … -0.034502048 -0.1749487; -0.049912814 0.18857534 … -0.038297735 -0.17626214], bias = Float32[-0.06764558, 0.11025448, -0.07224047, 0.07128799, -0.053267643, -0.07598649, -0.05409752, -0.10398945, 0.11784546, -0.103827655]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can inspect the structure of the parameters:\n",
    "Lux.display(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e949064-fe86-4870-89cb-7d02dc38cbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_function (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Loss Function and Optimizer Setup ---\n",
    "\n",
    "# The loss function must take the model, parameters, state, and data as arguments.\n",
    "# It returns the loss value and the (potentially updated) state.\n",
    "function loss_function(model, ps, st, x, y)\n",
    "    y_pred, st_new = model(x, ps, st)\n",
    "    loss = logitcrossentropy(y_pred, y)\n",
    "    return loss, st_new\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e708c19-b678-4b79-9283-741c483b850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 1:   0%|▏                                         |  ETA: 0:27:44\u001b[39m\n",
      "\u001b[A4m   loss: 2.4095874\u001b[39m\n",
      "\u001b[32mEpoch 1: 100%|██████████████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "\u001b[34m   loss: 0.13186748\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: Test Accuracy = 95.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 2:  19%|███████▉                                  |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.07697785\u001b[39m\n",
      "\u001b[32mEpoch 2:  40%|████████████████▊                         |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.13621089\u001b[39m\n",
      "\u001b[32mEpoch 2:  62%|██████████████████████████                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.124958545\u001b[39m\n",
      "\u001b[32mEpoch 2:  84%|███████████████████████████████████▎      |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.0916301\u001b[39m\n",
      "\u001b[32mEpoch 2: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.11521212\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: Test Accuracy = 96.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 3:  21%|████████▋                                 |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.07287196\u001b[39m\n",
      "\u001b[32mEpoch 3:  42%|█████████████████▉                        |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.04878325\u001b[39m\n",
      "\u001b[32mEpoch 3:  64%|██████████████████████████▉               |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.08716352\u001b[39m\n",
      "\u001b[32mEpoch 3:  85%|███████████████████████████████████▉      |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.13799715\u001b[39m\n",
      "\u001b[32mEpoch 3: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.0926114\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: Test Accuracy = 97.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 4:  22%|█████████▎                                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.14395942\u001b[39m\n",
      "\u001b[32mEpoch 4:  43%|██████████████████▏                       |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.054061525\u001b[39m\n",
      "\u001b[32mEpoch 4:  64%|███████████████████████████               |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.08021752\u001b[39m\n",
      "\u001b[32mEpoch 4:  85%|███████████████████████████████████▊      |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.055396523\u001b[39m\n",
      "\u001b[32mEpoch 4: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.044266265\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: Test Accuracy = 97.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 5:  21%|████████▋                                 |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.03425047\u001b[39m\n",
      "\u001b[32mEpoch 5:  41%|█████████████████▍                        |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.025607392\u001b[39m\n",
      "\u001b[32mEpoch 5:  62%|██████████████████████████                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.06354272\u001b[39m\n",
      "\u001b[32mEpoch 5:  83%|██████████████████████████████████▉       |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.014235704\u001b[39m\n",
      "\u001b[32mEpoch 5: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.028210139\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: Test Accuracy = 97.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 6:  22%|█████████▏                                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.035971403\u001b[39m\n",
      "\u001b[32mEpoch 6:  43%|██████████████████▏                       |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.03638174\u001b[39m\n",
      "\u001b[32mEpoch 6:  65%|███████████████████████████▌              |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.037897542\u001b[39m\n",
      "\u001b[32mEpoch 6:  87%|████████████████████████████████████▋     |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.037345223\u001b[39m\n",
      "\u001b[32mEpoch 6: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.057961807\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: Test Accuracy = 97.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 7:  17%|███████                                   |  ETA: 0:00:01\u001b[39m\n",
      "\u001b[A4m   loss: 0.03432457\u001b[39m\n",
      "\u001b[32mEpoch 7:  38%|███████████████▉                          |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.014777028\u001b[39m\n",
      "\u001b[32mEpoch 7:  59%|████████████████████████▊                 |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.019553546\u001b[39m\n",
      "\u001b[32mEpoch 7:  80%|█████████████████████████████████▋        |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.042672932\u001b[39m\n",
      "\u001b[32mEpoch 7: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.026678463\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: Test Accuracy = 97.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 8:  19%|████████▏                                 |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.0077943364\u001b[39m\n",
      "\u001b[32mEpoch 8:  39%|████████████████▎                         |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.011481822\u001b[39m\n",
      "\u001b[32mEpoch 8:  60%|█████████████████████████▍                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.021726256\u001b[39m\n",
      "\u001b[32mEpoch 8:  82%|██████████████████████████████████▎       |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.050892252\u001b[39m\n",
      "\u001b[32mEpoch 8: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.032553535\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8: Test Accuracy = 97.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 9:  20%|████████▌                                 |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.014968177\u001b[39m\n",
      "\u001b[32mEpoch 9:  41%|█████████████████                         |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.017752368\u001b[39m\n",
      "\u001b[32mEpoch 9:  62%|█████████████████████████▉                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.014934659\u001b[39m\n",
      "\u001b[32mEpoch 9:  83%|██████████████████████████████████▊       |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.009883834\u001b[39m\n",
      "\u001b[32mEpoch 9: 100%|██████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.016362146\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: Test Accuracy = 97.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mEpoch 10:  21%|████████▋                                |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.012205366\u001b[39m\n",
      "\u001b[32mEpoch 10:  42%|█████████████████▎                       |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.0042203614\u001b[39m\n",
      "\u001b[32mEpoch 10:  65%|██████████████████████████▋              |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.048551943\u001b[39m\n",
      "\u001b[32mEpoch 10:  88%|███████████████████████████████████▉     |  ETA: 0:00:00\u001b[39m\n",
      "\u001b[A4m   loss: 0.0048665786\u001b[39m\n",
      "\u001b[32mEpoch 10: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[34m   loss: 0.033069585\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10: Test Accuracy = 97.39%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer using Optimisers.jl\n",
    "# It takes the optimization rule (Adam) and the parameters to create the optimizer state.\n",
    "opt_state = Optimisers.setup(Adam(learning_rate), ps)\n",
    "\n",
    "# --- 5Training Loop (Explicitly written) ---\n",
    "println(\"\\nStarting training...\")\n",
    "\n",
    "for epoch in 1:num_epochs\n",
    "    p = Progress(length(train_loader); desc=\"Epoch $epoch: \")\n",
    "    \n",
    "    for (x_batch, y_batch) in train_loader\n",
    "        # Zygote.withgradient calculates the loss, the new state, and the gradients all at once.\n",
    "        (loss, st), grads = Zygote.withgradient(ps -> loss_function(model, ps, st, x_batch, y_batch), ps)\n",
    "        \n",
    "        # Update the optimizer state and the parameters\n",
    "        opt_state, ps = Optimisers.update!(opt_state, ps, grads[1])\n",
    "        \n",
    "        next!(p; showvalues=[(:loss, loss)]) # Update progress bar\n",
    "    end\n",
    "\n",
    "    # Evaluation step after each epoch\n",
    "    # In evaluation mode, we don't need gradients.\n",
    "    # The model call still requires `ps` and `st`.\n",
    "    y_hat_logits, _ = model(test_x, ps, st)\n",
    "    y_hat_labels = onecold(y_hat_logits) .- 1 # onecold is 1-based, labels are 0-based\n",
    "    \n",
    "    current_accuracy = mean(y_hat_labels .== test_y_raw)\n",
    "    println(\"\\nEpoch $epoch: Test Accuracy = \", round(current_accuracy * 100, digits=2), \"%\")\n",
    "end\n",
    "\n",
    "println(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec448d21-6942-47b0-a060-2c80d686da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating final model on the test set...\n",
      "-------------------------------------------\n",
      "Final Test Accuracy: 97.39%\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Final Evaluation ---\n",
    "println(\"\\nEvaluating final model on the test set...\")\n",
    "final_logits, _ = model(test_x, ps, st)\n",
    "final_predictions = onecold(final_logits) .- 1\n",
    "final_accuracy = mean(final_predictions .== test_y_raw)\n",
    "\n",
    "println(\"-------------------------------------------\")\n",
    "println(\"Final Test Accuracy: \", round(final_accuracy * 100, digits=2), \"%\")\n",
    "println(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ddd14-5743-4a35-89e4-346175cfb103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
