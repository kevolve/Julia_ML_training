{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d6febd-6f24-4672-a190-ab528f5cc659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/git/Julia_ML_training/unit5/Project.toml`\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[cbdf2221] \u001b[39mAlgebraOfGraphics v0.10.7\n",
      "  \u001b[90m[336ed68f] \u001b[39mCSV v0.10.15\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[13f3f980] \u001b[39mCairoMakie v0.13.9\n",
      "  \u001b[90m[a93c6f00] \u001b[39mDataFrames v1.7.0\n",
      "  \u001b[90m[31c24e10] \u001b[39mDistributions v0.25.120\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[587475ba] \u001b[39mFlux v0.16.3\n",
      "  \u001b[90m[38e38edf] \u001b[39mGLM v1.9.0\n",
      "  \u001b[90m[60bf3e95] \u001b[39mGLPK v1.2.1\n",
      "  \u001b[90m[09f84164] \u001b[39mHypothesisTests v0.11.5\n",
      "  \u001b[90m[4076af6c] \u001b[39mJuMP v1.26.0\n",
      "  \u001b[90m[23fbe1c1] \u001b[39mLatexify v0.16.8\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[b2108857] \u001b[39mLux v1.13.0\n",
      "  \u001b[90m[eb30cadb] \u001b[39mMLDatasets v0.7.18\n",
      "  \u001b[90m[add582a8] \u001b[39mMLJ v0.20.8\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[ee78f7c6] \u001b[39mMakie v0.22.9\n",
      "  \u001b[90m[ff71e718] \u001b[39mMixedModels v4.35.2\n",
      "  \u001b[90m[6f286f6a] \u001b[39mMultivariateStats v0.10.3\n",
      "  \u001b[90m[636a865e] \u001b[39mNearestNeighborModels v0.2.3\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[429524aa] \u001b[39mOptim v1.12.0\n",
      "  \u001b[90m[92933f4c] \u001b[39mProgressMeter v1.10.4\n",
      "  \u001b[90m[ce6b1742] \u001b[39mRDatasets v0.7.7\n",
      "  \u001b[90m[2913bbd2] \u001b[39mStatsBase v0.34.5\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[0c5d862f] \u001b[39mSymbolics v6.40.0\n",
      "  \u001b[90m[9e3dc215] \u001b[39mTimeSeries v0.24.2\n",
      "\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb9b81f-d1ce-4af1-9f20-3890b038f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: onehotbatch, onecold, logitcrossentropy, DataLoader\n",
    "using MLDatasets\n",
    "using Statistics\n",
    "using Random\n",
    "using ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5edc5e-7281-4a68-b714-60f2426c4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(0)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "num_epochs = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe11362-7b89-4db1-8ffa-ba354d154304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 60000), (60000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_raw, train_y_raw = MNIST(split=:train)[:]\n",
    "test_x_raw,  test_y_raw  = MNIST(split=:test)[:]\n",
    "size(train_x_raw), size(train_y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250eea6f-7594-443c-981b-26ef482e7596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess_features (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The neural network expects vector inputs, not 2D images.\n",
    "# We also convert the data to Float32 for performance.\n",
    "# Final shape will be (features, num_samples), e.g., (784, 60000)\n",
    "function preprocess_features(x)\n",
    "    return Float32.(reshape(x, 28*28, :))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d7bd4d-e6c1-4ff3-ae32-408c2f10b2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 60000), (784, 10000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = preprocess_features(train_x_raw)\n",
    "test_x = preprocess_features(test_x_raw)\n",
    "size(train_x), size(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c2d566-32f6-4cad-895b-48ea6093393c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 60000), (10, 10000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The crossentropy loss function expects labels to be \"one-hot\" encoded.\n",
    "# E.g., the label '2' becomes a vector: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "# The range 0:9 specifies all possible classes.\n",
    "train_y = onehotbatch(train_y_raw, 0:9)\n",
    "test_y = onehotbatch(test_y_raw, 0:9)\n",
    "size(train_y), size(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b647e9d2-5acc-4a71-b921-bf9220c8ba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, Bool[0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's consider the first label as an example\n",
    "train_y_raw[1], train_y[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528501bd-7bff-417d-bb84-d6f92b5fb683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469-element DataLoader(::Tuple{Matrix{Float32}, OneHotArrays.OneHotMatrix{UInt32, Vector{UInt32}}}, shuffle=true, batchsize=128)\n",
       "  with first element:\n",
       "  (784×128 Matrix{Float32}, 10×128 OneHotMatrix(::Vector{UInt32}) with eltype Bool,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataLoader to automatically handle batching and shuffling\n",
    "train_loader = DataLoader((train_x, train_y), batchsize=batch_size, shuffle=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9dc0cd-2990-4123-ba98-7e25883c3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(784 => 128, relu),              \u001b[90m# 100_480 parameters\u001b[39m\n",
       "  Dense(128 => 64, relu),               \u001b[90m# 8_256 parameters\u001b[39m\n",
       "  Dense(64 => 10),                      \u001b[90m# 650 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m109_386 parameters, 427.594 KiB."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple 3-layer sequential model (2 hidden layers, 1 output layer)\n",
    "model = Chain(\n",
    "      Dense(28*28, 128, relu),  # Input: 784 -> Hidden 1: 128 neurons, with ReLU activation\n",
    "      Dense(128, 64, relu),     # Hidden 1: 128 -> Hidden 2: 64 neurons, with ReLU activation\n",
    "      Dense(64, 10)             # Hidden 2: 64 -> Output: 10 neurons (for digits 0-9)\n",
    ")\n",
    "# Note: No activation on the last layer. `crossentropy` expects raw logits for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19b36f0-33b3-4c84-aa78-03970c156e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `logitcrossentropy` is the standard loss for multi-class classification.\n",
    "# It works on the raw model outputs (logits).\n",
    "loss(m, x, y) = logitcrossentropy(m(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c192adc4-00ea-4d05-943c-5fafcef1270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer with the model's parameters\n",
    "opt_state = Flux.setup(ADAM(learning_rate), model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81919a86-689a-42b0-85c4-503c21319113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "  6.735494 seconds (34.47 M allocations: 2.218 GiB, 3.46% gc time, 93.61% compilation time)\n",
      "Epoch 1: Test Accuracy = 95.41%\n",
      "  0.459711 seconds (152.44 k allocations: 558.265 MiB, 6.93% gc time)\n",
      "Epoch 2: Test Accuracy = 96.35%\n",
      "  0.412442 seconds (152.44 k allocations: 558.265 MiB, 5.55% gc time)\n",
      "Epoch 3: Test Accuracy = 97.12%\n",
      "  0.399418 seconds (152.44 k allocations: 558.265 MiB, 4.65% gc time)\n",
      "Epoch 4: Test Accuracy = 97.37%\n",
      "  0.397601 seconds (152.44 k allocations: 558.265 MiB, 4.39% gc time)\n",
      "Epoch 5: Test Accuracy = 97.22%\n",
      "  0.438921 seconds (152.44 k allocations: 558.265 MiB, 4.41% gc time)\n",
      "Epoch 6: Test Accuracy = 97.25%\n",
      "  0.398900 seconds (152.44 k allocations: 558.265 MiB, 4.45% gc time)\n",
      "Epoch 7: Test Accuracy = 97.67%\n",
      "  0.392282 seconds (152.44 k allocations: 558.265 MiB, 3.94% gc time)\n",
      "Epoch 8: Test Accuracy = 97.73%\n",
      "  0.401077 seconds (152.44 k allocations: 558.265 MiB, 4.03% gc time)\n",
      "Epoch 9: Test Accuracy = 97.8%\n",
      "  0.391978 seconds (152.44 k allocations: 558.265 MiB, 3.99% gc time)\n",
      "Epoch 10: Test Accuracy = 97.74%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nStarting training...\")\n",
    "\n",
    "# Training Loop\n",
    "for epoch in 1:num_epochs\n",
    "    # Flux.train! handles the entire training step for one epoch:\n",
    "    # it iterates through the `train_loader`, calculates loss,\n",
    "    # computes gradients, and updates the model parameters.\n",
    "    @time Flux.train!(loss, model, train_loader, opt_state)\n",
    "    \n",
    "    # Optional: Calculate and print accuracy on the test set after each epoch\n",
    "    # Get model's predictions (logits)\n",
    "    y_hat_logits = model(test_x)\n",
    "    # Convert logits to class labels (0-9)\n",
    "    y_hat_labels = onecold(y_hat_logits, 0:9)\n",
    "    # Compare with true labels and calculate the mean\n",
    "    current_accuracy = mean(y_hat_labels .== test_y_raw)\n",
    "    \n",
    "    println(\"Epoch $epoch: Test Accuracy = \", round(current_accuracy * 100, digits=2), \"%\")\n",
    "end\n",
    "\n",
    "println(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d316479a-0c61-45c9-b3e9-96279ae9e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Prediction:\n",
      "  - True Label:      7\n",
      "  - Predicted Label: 7\n",
      "  - Result: Correct! ✅\n"
     ]
    }
   ],
   "source": [
    "# Let's predict a single image from the test set\n",
    "println(\"\\nExample Prediction:\")\n",
    "index = 42 # Let's test the 42nd image\n",
    "single_image = test_x[:, index]\n",
    "true_label = test_y_raw[index]\n",
    "# Get the model's raw output (logits) for this single image\n",
    "prediction_logits = model(single_image)\n",
    "# Find the class with the highest score\n",
    "predicted_label = onecold(prediction_logits, 0:9)[1]\n",
    "\n",
    "println(\"  - True Label:      \", true_label)\n",
    "println(\"  - Predicted Label: \", predicted_label)\n",
    "if predicted_label == true_label\n",
    "    println(\"  - Result: Correct! ✅\")\n",
    "else\n",
    "    println(\"  - Result: Incorrect! ❌\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0444f256-c8e5-4c21-928c-450a46b1eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Final Test Accuracy: 97.74%\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get final predictions and calculate accuracy\n",
    "final_predictions = onecold(model(test_x), 0:9)\n",
    "final_accuracy = mean(final_predictions .== test_y_raw)\n",
    "println(\"-------------------------------------------\")\n",
    "println(\"Final Test Accuracy: \", round(final_accuracy * 100, digits=2), \"%\")\n",
    "println(\"-------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
